import os
import time
import h5py
import numpy as np
import tensorflow as tf
import voxelmorph as vxm
import neurite as ne
import skimage
import matplotlib.pyplot as plt
import pyvista as pv

def test_data_generator(hdf5_file, patch_size=(128, 128, 128), stride=(64, 64, 64)):
    """
    Generator that extracts consecutive patches from a 3D volume, processes them, 
    and then stitches them back together for one sample.

    Args:
        hdf5_file: Path to the HDF5 file containing the volume data.
        patch_size: Size of the 3D patches to extract.
        stride: The step size between consecutive patches.
    
    Yields:
        A tuple of stitched volumes (moved image, displacement field) reconstructed from the processed patches.
    """
    hf = h5py.File(hdf5_file, 'r')
    num_samples = len(hf.keys()) // 2  # Assuming paired 'static' and 'moving' datasets
    vol_shape = hf['static_0'].shape

    # Calculate the necessary padding for each dimension
    pad = [(0, (patch_size[i] - (vol_shape[i] % patch_size[i])) % patch_size[i]) for i in range(len(vol_shape))]
    
    for idx in range(num_samples):
        moving_image = hf[f'moving_{idx}'][...]
        fixed_image = hf[f'static_{idx}'][...]

        # Apply padding to the images
        padded_moving = np.pad(moving_image, pad, mode='constant', constant_values=0)
        padded_fixed = np.pad(fixed_image, pad, mode='constant', constant_values=0)
        padded_vol_shape = padded_moving.shape

        # Calculate the number of patches in each dimension
        patches_per_dim = [(padded_vol_shape[i] - patch_size[i]) // stride[i] + 1 for i in range(len(padded_vol_shape))]

        # Initialize empty arrays for the stitched moved image and displacement field
        reconstructed_moved = np.zeros(padded_vol_shape)
        reconstructed_displacement = np.zeros((*padded_vol_shape, 3))
        weight_volume = np.zeros(padded_vol_shape)  # To handle overlapping regions

        for z in range(patches_per_dim[0]):
            for y in range(patches_per_dim[1]):
                for x in range(patches_per_dim[2]):
                    start_z = z * stride[0]
                    start_y = y * stride[1]
                    start_x = x * stride[2]

                    # Extract patch
                    moving_patch = padded_moving[start_z:start_z + patch_size[0],
                                                 start_y:start_y + patch_size[1],
                                                 start_x:start_x + patch_size[2]]

                    # Normalize the patch
                    #moving_patch = (moving_patch - np.min(moving_patch)) / (np.max(moving_patch) - np.min(moving_patch))

                    # Prepare input for the model
                    patch_input = np.expand_dims(moving_patch, axis=-1)  # Add channel dimension
                    fixed_patch = padded_fixed[start_z:start_z + patch_size[0],
                                               start_y:start_y + patch_size[1],
                                               start_x:start_x + patch_size[2]]
                    fixed_patch = np.expand_dims(fixed_patch, axis=-1)
                    inputs = [np.expand_dims(patch_input, axis=0), np.expand_dims(fixed_patch, axis=0)]
                    
                    # Model prediction
                    processed_patch, displacement_patch = vxm_model.predict(inputs)
                    processed_patch = processed_patch.squeeze()
                    displacement_patch = displacement_patch.squeeze()

                    # Stitch the processed patch and displacement vector back into the reconstructed volumes
                    reconstructed_moved[start_z:start_z + patch_size[0],
                                        start_y:start_y + patch_size[1],
                                        start_x:start_x + patch_size[2]] += processed_patch

                    reconstructed_displacement[start_z:start_z + patch_size[0],
                                               start_y:start_y + patch_size[1],
                                               start_x:start_x + patch_size[2], :] += displacement_patch
                    
                    weight_volume[start_z:start_z + patch_size[0],
                                  start_y:start_y + patch_size[1],
                                  start_x:start_x + patch_size[2]] += 1

        # Normalize to handle overlapping regions
        reconstructed_moved /= np.maximum(weight_volume, 1)  # Avoid division by zero
        reconstructed_displacement /= np.maximum(weight_volume[..., np.newaxis], 1)  # Normalize the vector field

        # Crop the padded area out to restore the original volume shape
        reconstructed_moved = reconstructed_moved[:vol_shape[0], :vol_shape[1], :vol_shape[2]]
        reconstructed_displacement = reconstructed_displacement[:vol_shape[0], :vol_shape[1], :vol_shape[2], :]

        yield reconstructed_moved, reconstructed_displacement, fixed_image  # Yield the reconstructed volumes and fixed image


def save_moved_image_as_vtk(moved_image, filename):
    # Create a PyVista grid for the moved image
    moved_image_shape = moved_image.shape
    x = np.arange(moved_image_shape[0])
    y = np.arange(moved_image_shape[1])
    z = np.arange(moved_image_shape[2])
    grid = pv.StructuredGrid(*np.meshgrid(x, y, z, indexing="ij"))

    # Add the moved image data to the grid
    grid["moved_image"] = moved_image.flatten(order="F")  # Flatten in Fortran order

    # Save the moved image grid to a VTK file
    grid.save(filename)

# Function to save the displacement vector field as a VTK file
def save_displacement_vector_as_vtk(displacement_vector, filename):
    # Create a PyVista grid for the displacement vector
    vector_shape = displacement_vector.shape[:-1]
    x = np.arange(vector_shape[0])
    y = np.arange(vector_shape[1])
    z = np.arange(vector_shape[2])
    grid = pv.StructuredGrid(*np.meshgrid(x, y, z, indexing="ij"))

    # Add the displacement vector data to the grid
    vectors = np.zeros((np.prod(vector_shape), 3))
    for i in range(3):
        vectors[:, i] = displacement_vector[..., i].flatten(order="F")
    grid["displacement"] = vectors

    # Save the displacement vector grid to a VTK file
    grid.save(filename)

def plot_history(history, loss_name='loss'):
    fig, ax = plt.subplots()
    ax.plot(history.history[loss_name], label='Training Loss')
    if 'val_' + loss_name in history.history:
        ax.plot(history.history['val_' + loss_name], label='Validation Loss')
    ax.set_ylabel('Loss')
    ax.set_xlabel('Epoch')
    ax.set_title('History of ' + loss_name, fontsize=12)
    ax.legend()
    plt.show()

def vxm_data_generator(hdf5_file, patch_size=(128, 128, 128), batch_size=1, normalization='min-max'):
    """
    Generator that loads data from an HDF5 file and yields data for
    the VoxelMorph model using corresponding random patches.
    
    inputs:  moving [bs, D, H, W, 1], fixed image [bs, D, H, W, 1]
    outputs: moved image [bs, D, H, W, 1], zero-gradient [bs, D, H, W, 3]


    """
    #print('Generator function called')
    hf = h5py.File(hdf5_file, 'r')
    num_samples = len(hf.keys()) // 2  # Assuming paired 'static' and 'moving' datasets
    vol_shape = hf['static_0'].shape
    ndims = len(vol_shape)
    #print('Data loaded')
    # zero array for deformation field
    zero_phi = np.zeros([batch_size, *patch_size, ndims])

    def extract_random_patch(image, start_coords):
        start_x, start_y, start_z = start_coords
        patch = image[start_x:start_x + patch_size[0], start_y:start_y + patch_size[1], start_z:start_z + patch_size[2]]
        return np.expand_dims(patch, axis=-1)  # Add channel dimension

    def normalize(image, method):
        if method == 'min-max':
            min_val = np.min(image)
            max_val = np.max(image)
            return (image - min_val) / (max_val - min_val)
        elif method == 'standard':
            mean_val = np.mean(image)
            std_val = np.std(image)
            return (image - mean_val) / std_val
        else:
            raise ValueError(f"Unknown normalization method: {method}")
   
    # start infinite loop
    while True:
        moving_patches = []
        fixed_patches = []
        #print('Empty patches initialized')
        
        while len(moving_patches) < batch_size:
            idx = np.random.randint(0, num_samples)
            print(f'Loading sample index: {idx}')
            moving_image = hf[f'moving_{idx}'][...]
            fixed_image = hf[f'static_{idx}'][...]

            max_x = moving_image.shape[0] - patch_size[0]
            max_y = moving_image.shape[1] - patch_size[1]
            max_z = moving_image.shape[2] - patch_size[2]

            start_x = np.random.randint(0, max_x + 1)
            start_y = np.random.randint(0, max_y + 1)
            start_z = np.random.randint(0, max_z + 1)
            start_coords = (start_x, start_y, start_z)
            #print(f'Extracting random patch starting at: {start_coords}')
            moving_patch = extract_random_patch(moving_image, start_coords)
            fixed_patch = extract_random_patch(fixed_image, start_coords)
            #print('Random patch extract')
            #moving_patch = normalize(moving_patch, normalization)
            #fixed_patch = normalize(fixed_patch, normalization)
            
            moving_patches.append(moving_patch)
            fixed_patches.append(fixed_patch)
            #print(f'Patches collected: {len(moving_patches)}')

        moving_patches = np.array(moving_patches)
        fixed_patches = np.array(fixed_patches)
        #print('Patches converted to array')

        inputs = [moving_patches, fixed_patches]
        outputs = [fixed_patches, zero_phi]
        #print("Yielding a batch of data...")
        yield (inputs, outputs)

def plot_patches(inputs, outputs, patch_size=(128, 128, 128)):
    """
    Function to plot corresponding random image patches from inputs and outputs.
    
    inputs:  List of numpy arrays [moving_patches, fixed_patches]
    outputs: List of numpy arrays [fixed_patches, zero_phi]
    patch_size: Size of the 3D patches
    """
    moving_patches, fixed_patches = inputs
    fixed_patches_out, zero_phi = outputs
    
    batch_size = moving_patches.shape[0]
    fig, axes = plt.subplots(batch_size, 3, figsize=(15, 5 * batch_size))
    
    for i in range(batch_size):
        ax1, ax2, ax3 = axes[i] if batch_size > 1 else axes

        # Extracting central slice for visualization
        moving_slice = moving_patches[i, ..., 0][patch_size[0] // 2, :, :]
        fixed_slice_in = fixed_patches[i, ..., 0][patch_size[0] // 2, :, :]
        fixed_slice_out = fixed_patches_out[i, ..., 0][patch_size[0] // 2, :, :]
        
        ax1.imshow(moving_slice, cmap='gray')
        ax1.set_title(f'Moving Image Patch {i+1}')
        
        ax2.imshow(fixed_slice_in, cmap='gray')
        ax2.set_title(f'Fixed Image Patch (Input) {i+1}')
        
        ax3.imshow(fixed_slice_out, cmap='gray')
        ax3.set_title(f'Fixed Image Patch (Output) {i+1}')
    
    plt.tight_layout()
    plt.show()


# Paths to the HDF5 files
train_hdf5 = r'/home/kchand/deform_reg_project/train_cleaned_data.h5'
test_hdf5 = r'/home/kchand/deform_reg_project/test_cleaned_data.h5'

# Generate batch data
train_generator = vxm_data_generator(train_hdf5, patch_size=(256, 256, 256),batch_size=5,  normalization='min-max')
val_generator = vxm_data_generator(test_hdf5, batch_size=1)

# Get sample data for input shapes
in_sample, out_sample = next(train_generator)
plot_patches(in_sample, out_sample, patch_size=(256, 256, 256))

print(f"in_sample shape: {in_sample[0].shape}, {in_sample[1].shape}")
print(f"out_sample shape: {out_sample[0].shape}, {out_sample[1].shape}")

# Determine volume shape and features for the VoxelMorph model
vol_shape = in_sample[0].shape[1:4]
nb_features = [
    [32, 32, 32, 32],         # encoder features
    [32, 32, 32, 32, 32, 16]  # decoder features
]

# Initialize the VoxelMorph model with 3D convolutions
vxm_model = vxm.networks.VxmDense(vol_shape, nb_features, int_steps=0)
#losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]
losses = [vxm.losses.NCC().loss, vxm.losses.Grad('l2').loss]
lambda_param = 0.05
loss_weights = [1, lambda_param]

vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights)

# Train the model
start_time = time.time()
#number of times the model will go through the entire training dataset
nb_epochs = 10
#number of batches to draw from the generator for each epoch
steps_per_epoch = 10
hist = vxm_model.fit(train_generator, epochs=nb_epochs, steps_per_epoch=steps_per_epoch, verbose=2)
end_time = time.time()
elapsed_time = (end_time - start_time) / 60
print(f"Time taken to complete training: {elapsed_time:.2f} minutes")

#visualize history 
plot_history(hist)

# Validation
val_input, _ = next(val_generator)
val_pred = vxm_model.predict(val_input)

# Initialize the test generator
test_generator = test_data_generator(test_hdf5, patch_size=(128, 128, 128), stride=(64, 64, 64))

# Get the output for just one sample
reconstructed_moved, reconstructed_displacement, fixed_image = next(test_generator)

# Assuming you have the following arrays from your model prediction
moved_image = val_pred[0].squeeze()  # Moved image
displacement_vector = val_pred[1].squeeze()  # Displacement vector field

# visualize registration
images = [img[0, :, :, 0] for img in val_input + val_pred] 
titles = ['moving', 'fixed', 'moved', 'flow']
ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);


# Visualization
def plot_3d_slices(images, titles=None, cmaps=['gray'], do_colorbars=True):
    nb_vis = len(images)
    fig, axes = plt.subplots(1, nb_vis, figsize=(15, 5))
    for i, img in enumerate(images):
        ax = axes[i]
        ax.imshow(np.sum(img, axis=0), cmap=cmaps[i % len(cmaps)])
        if titles:
            ax.set_title(titles[i])
        if do_colorbars:
            plt.colorbar(ax.imshow(np.sum(img, axis=0), cmap=cmaps[i % len(cmaps)]), ax=ax)
    plt.show()

images = [img[0, ..., 0] for img in val_input + val_pred]
titles = ['moving', 'fixed', 'moved', 'flow']
plot_3d_slices(images, titles=titles, cmaps=['gray'])
